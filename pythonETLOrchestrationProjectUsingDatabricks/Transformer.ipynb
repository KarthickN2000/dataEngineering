{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e536bac4-3cd9-437c-a6aa-f384d66d5220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755953e0-679c-4a98-b0e6-63a5b774a785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"thebigdatashow.me\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce2e201-a226-4cca-a78e-3a590505f8f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x7fbf50b84af0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0f5a52a-d1a8-4577-9e75-024db097ca58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def transform(self,inputDFs):\n",
    "        pass\n",
    "\n",
    "class FirstTransformation(Transform):\n",
    "    def transform(self,inputDFs):\n",
    "        inputdf = inputDFs.get(\"transactiondf\")\n",
    "\n",
    "        windowSpec = Window.partitionBy(col(\"customer_id\")).orderBy(col(\"transaction_date\"))\n",
    "\n",
    "        transformdf = inputdf.withColumn(\"nextProductName\",lead(col(\"product_name\")).over(windowSpec))\n",
    "\n",
    "        \n",
    "\n",
    "        filterdf = transformdf.filter((col(\"product_name\") == \"iPhone\") &\n",
    "                                      (col(\"nextProductName\") == \"AirPods\"))\n",
    "        filterdf.orderBy(col(\"customer_id\"),col(\"transaction_date\")).display()\n",
    "\n",
    "\n",
    "        #customerdf codes\n",
    "        customerdata = inputDFs.get(\"customerdf\")\n",
    "        customerdata.show()\n",
    "\n",
    "        #joining two dfs\n",
    "\n",
    "        joined_df = filterdf.join(customerdata,\"customer_id\")\n",
    "\n",
    "        return joined_df\\\n",
    "               .select('customer_id','customer_name','location')\n",
    "               \n",
    "        \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "066828bc-c95c-4fc6-8583-cfd3cee03fc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "class OnlyAirpodsAndIphone:\n",
    "    def transform(self,inputdfs):\n",
    "        inputdf = inputdfs.get(\"transactiondf\")\n",
    "\n",
    "        groupeddf = inputdf.groupBy(col(\"customer_id\")).agg(collect_set(col(\"product_name\")).alias(\"list_of_products\"))\n",
    "\n",
    "        filterdf = groupeddf.filter((array_contains(col(\"list_of_products\"),\"iPhone\")) &\n",
    "                                    (array_contains(col(\"list_of_products\"),\"AirPods\")) &\n",
    "                                     (size(col(\"list_of_products\"))==2))\n",
    "        customer_data = inputdfs.get(\"customerdf\")\n",
    "\n",
    "        joineddf = customer_data.join(broadcast(filterdf),\"customer_id\")\n",
    "\n",
    "        return joineddf.select(\"customer_id\",\"list_of_products\",\"location\")\n",
    "                \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Transformer",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}